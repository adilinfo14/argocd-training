# Ollama

Ollama déployé sur Kubernetes (K3s) via ArgoCD (GitOps).
Service IA interne pour modèles LLM.
